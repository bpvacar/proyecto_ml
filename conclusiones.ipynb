{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para SVM con este flujo obtuvimos:\n",
    "\n",
    "F1 (samples) en CV: 0.5261\n",
    "F1 (samples) en validación: 0.5028\n",
    "Test (tras aplicar umbrales óptimos):\n",
    "micro-F1≈0.50, micro-recall≈0.57, micro-precision≈0.45\n",
    "La clase más frecuente (etiqueta 3) alcanza F1≈0.75, mientras que algunas de soporte menor (p. ej. clases 2 y 4) quedan alrededor de F1≈0.32–0.46.\n",
    "\n",
    "\n",
    "Este flujo con SVM demuestra ser sólido para clases dominantes y alcanza un F1-samples estable en torno a 0.50, pero muestra limitaciones en las categorías menos representadas. Para mejorar la precision en conjunto sin sacrificar el recall, convendría explorar ajustes de umbral por etiqueta, reforzar el entrenamiento de las clases raras (más datos o técnicas de oversampling) y/o combinarlo con otros modelos (ensamble) que compensen sus puntos débiles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la red neuronal (MLP + BCEWithLogitsLoss) con el flujo de Lightning obtuvimos:\n",
    "\n",
    "F1-samples medio en validación cruzada (10×2): ≈ 0.47\n",
    "Hamming loss medio en CV: ≈ 0.31\n",
    "F1-samples en validación hold-out: ≈ 0.45\n",
    "Hamming loss en validación hold-out: ≈ 0.31\n",
    "Test final (usando los mejores checkpoints):\n",
    "F1-samples ≈ 0.48\n",
    "Hamming loss ≈ 0.30\n",
    "\n",
    "\n",
    "Este flujo con NN demuestra ser estable, puesto que Hamming ≈ 0.30 significa que el modelo acierta alrededor del 70 % de las decisiones etiqueta-a-etiqueta, lo cuál claramente es lejos de lo ideal (< 0.10) pero llega a ser aleatoreao, el F1 por otro lado, deja en claro que hay  una solidez aceptable en las clases frecuentes, aunque las minoritarias moderen la media global."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
